"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∏.
–ü–æ–º–æ–∂–µ—Ç –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å RTX 2060 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
"""

import subprocess
import sys

def check_gpu_support():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—É—â–µ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ GPU."""
    print("=== –ü–†–û–í–ï–†–ö–ê GPU –ü–û–î–î–ï–†–ñ–ö–ò ===")
    
    try:
        import torch
        print(f"‚úÖ PyTorch —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {torch.__version__}")
        
        cuda_available = torch.cuda.is_available()
        print(f"CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {'‚úÖ –î–∞' if cuda_available else '‚ùå –ù–µ—Ç'}")
        
        if cuda_available:
            device_count = torch.cuda.device_count()
            print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {device_count}")
            
            for i in range(device_count):
                gpu_name = torch.cuda.get_device_name(i)
                props = torch.cuda.get_device_properties(i)
                memory_gb = props.total_memory / 1024**3
                compute_capability = f"{props.major}.{props.minor}"
                
                print(f"GPU {i}: {gpu_name}")
                print(f"  –ü–∞–º—è—Ç—å: {memory_gb:.1f} –ì–ë")
                print(f"  Compute Capability: {compute_capability}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å RTX 2060
                if "2060" in gpu_name:
                    print(f"  üéØ RTX 2060 –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞! –û—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è.")
                    
            if torch.version.cuda:
                print(f"CUDA –≤–µ—Ä—Å–∏—è PyTorch: {torch.version.cuda}")
            else:
                print("‚ùå PyTorch —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ë–ï–ó –ø–æ–¥–¥–µ—Ä–∂–∫–∏ CUDA")
                return False
                
        else:
            print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            return False
            
        return True
        
    except ImportError:
        print("‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ: {e}")
        return False

def install_cuda_pytorch():
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA."""
    print("\n=== –£–°–¢–ê–ù–û–í–ö–ê PYTORCH –° CUDA ===")
    
    print("–£–¥–∞–ª–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ PyTorch...")
    subprocess.run([sys.executable, "-m", "pip", "uninstall", "torch", "torchvision", "-y"])
    
    print("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA 11.8 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è RTX 2060)...")
    result = subprocess.run([
        sys.executable, "-m", "pip", "install", 
        "torch", "torchvision", 
        "--index-url", "https://download.pytorch.org/whl/cu118"
    ])
    
    if result.returncode == 0:
        print("‚úÖ PyTorch —Å CUDA —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        return True
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ PyTorch —Å CUDA")
        return False

def test_gpu_performance():
    """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GPU."""
    print("\n=== –¢–ï–°–¢ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò GPU ===")
    
    try:
        import torch
        import time
        
        if not torch.cuda.is_available():
            print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return
        
        device = torch.device('cuda')
        print(f"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞: {torch.cuda.get_device_name(0)}")
        
        # –¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        size = 1000
        print(f"–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü {size}x{size}...")
        
        # CPU —Ç–µ—Å—Ç
        start_time = time.time()
        a_cpu = torch.randn(size, size)
        b_cpu = torch.randn(size, size)
        c_cpu = torch.mm(a_cpu, b_cpu)
        cpu_time = time.time() - start_time
        
        # GPU —Ç–µ—Å—Ç
        start_time = time.time()
        a_gpu = torch.randn(size, size, device=device)
        b_gpu = torch.randn(size, size, device=device)
        torch.cuda.synchronize()  # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π
        
        start_compute = time.time()
        c_gpu = torch.mm(a_gpu, b_gpu)
        torch.cuda.synchronize()
        gpu_time = time.time() - start_compute
        
        print(f"CPU –≤—Ä–µ–º—è: {cpu_time:.3f} —Å–µ–∫")
        print(f"GPU –≤—Ä–µ–º—è: {gpu_time:.3f} —Å–µ–∫")
        print(f"–£—Å–∫–æ—Ä–µ–Ω–∏–µ: {cpu_time/gpu_time:.1f}x")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ GPU
        memory_allocated = torch.cuda.memory_allocated() / 1024**2
        memory_reserved = torch.cuda.memory_reserved() / 1024**2
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU –ø–∞–º—è—Ç–∏: {memory_allocated:.1f} –ú–ë")
        print(f"–ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ: {memory_reserved:.1f} –ú–ë")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")

def check_nvidia_driver():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–∞ NVIDIA."""
    print("\n=== –ü–†–û–í–ï–†–ö–ê –î–†–ê–ô–í–ï–†–ê NVIDIA ===")
    
    try:
        result = subprocess.run(["nvidia-smi"], capture_output=True, text=True)
        if result.returncode == 0:
            print("‚úÖ –î—Ä–∞–π–≤–µ—Ä NVIDIA —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω:")
            print(result.stdout)
        else:
            print("‚ùå nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω")
            print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä NVIDIA —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞")
    except FileNotFoundError:
        print("‚ùå nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä NVIDIA —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ GPU."""
    print("=== –ù–ê–°–¢–†–û–ô–ö–ê GPU –î–õ–Ø –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø –ü–û–ò–°–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô ===")
    print("–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –ø–æ–º–æ–∂–µ—Ç –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å RTX 2060 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã")
    print()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–∞
    check_nvidia_driver()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    gpu_ready = check_gpu_support()
    
    if not gpu_ready:
        print("\nüîß CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ù—É–∂–Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA.")
        
        response = input("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA? (y/n): ").lower()
        if response == 'y':
            success = install_cuda_pytorch()
            if success:
                print("\nüîÑ –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–∫—É...")
                gpu_ready = check_gpu_support()
            else:
                print("‚ùå –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å")
                return
    
    if gpu_ready:
        print("\nüöÄ GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≥–æ—Ç–æ–≤–∞!")
        test_gpu_performance()
        
        print("\n=== –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ===")
        print("‚úÖ –í–∞—à–∞ RTX 2060 –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        print("‚úÖ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU")
        print("‚úÖ –û–∂–∏–¥–∞–µ–º–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: 3-10x –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å CPU")
        print("‚úÖ –ú–æ–∂–µ—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –≤ config.py –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        
    else:
        print("\n‚ùå GPU –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞")
        print("–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:")
        print("1. –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥—Ä–∞–π–≤–µ—Ä NVIDIA")
        print("2. –£—Å—Ç–∞—Ä–µ–≤—à–∏–π –¥—Ä–∞–π–≤–µ—Ä")
        print("3. –ü—Ä–æ–±–ª–µ–º—ã —Å PyTorch")
        print("\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥—Ä–∞–π–≤–µ—Ä –Ω–∞ —Å–∞–π—Ç–µ NVIDIA –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫—É")

if __name__ == "__main__":
    main()
    input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
